services:
  notebook:
    image: wenyixu101/notebook:latest
    container_name: notebook
    ports:
      - "8888:8888"
    environment:
      - JUPYTER_ENABLE_LAB=no
      - ENVIRONMENT=development
      - PYSPARK_SUBMIT_ARGS=--packages io.delta:delta-core_2.12:2.1.0 --conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog pyspark-shell
    command: "start-notebook.sh --NotebookApp.default_url=/tree --NotebookApp.token='' --NotebookApp.password=''"
    volumes:
      - ./data:/opt/data
    pull_policy: always
    deploy:
      resources:
        limits:
          cpus: "1" 
          memory: 1g

  spark-master:
    image: wenyixu101/spark:latest
    container_name: spark-master
    ports:
      - "4040:4040"
      - "8080:8080"
      - "7077:7077"
    environment:
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MODE=master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    command: "/opt/spark/bin/spark-class org.apache.spark.deploy.master.Master"
    volumes:
      - ./data:/opt/data
    pull_policy: always
    deploy:
      resources:
        limits:
          cpus: "1" 
          memory: 1g

  spark-worker:
    image: wenyixu101/spark:latest
    container_name: spark-worker
    ports:
      - "8081:8081"
    environment:
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MODE=worker
      - SPARK_WORKER_PORT=8081
      - SPARK_WORKER_WEBUI_PORT=8081
    command: "/opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077"
    volumes:
      - ./data:/opt/data
    pull_policy: always
    deploy:
      resources:
        limits:
          cpus: "1" 
          memory: 1g